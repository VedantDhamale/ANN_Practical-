{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs,b,t,rho,learning_rate,n):\n",
    "    print(\"Initially the Bottom-up weights b=\",b,\"\\n\")\n",
    "    print(\"Initially the Top-down weights t = \",t,\"\\n\")\n",
    "    for s in inputs:\n",
    "        print(\"S = \",s)\n",
    "        norm_s=np.sum(s)\n",
    "        print(\"||s|| = \",norm_s,\"\\n\")\n",
    "        x=s\n",
    "        y=np.dot(x,b)\n",
    "        print(\"y = bij*xi \",y)\n",
    "        J=winner(y)\n",
    "        print(\"Winner J = \",J,\"\\n\")\n",
    "\n",
    "        xi=s*t[J]\n",
    "        print(\"xi = Si*tJi = \",xi)\n",
    "        norm_x=np.sum(xi)\n",
    "        print(\"||x||\",norm_x)\n",
    "        test_reset=norm_x/norm_s\n",
    "        print(\"||x||/||s|| = \",test_reset)\n",
    "        print(\"rho = \",rho)\n",
    "        if(test_reset>=rho):\n",
    "            print(\"Reset is False \\n\")\n",
    "            for i in range(n):\n",
    "                b[i][J]=learning_rate*xi[i]/(learning_rate-1+norm_x)\n",
    "                t[J][i]=xi[i]\n",
    "            print(\"bij(new) = \",b,\"\\n\")\n",
    "            print(\"tji(new) = \",t,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(y):\n",
    "    j=0\n",
    "    for i in range(len(y)):\n",
    "        if(y[i]>y[j]):\n",
    "            j=i\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[0, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [1, 0, 0, 0]])\n",
    "rho = 0.4 #vigilance parameter \n",
    "learning_rate = 2 \n",
    "n = 4 #no of components in vector\n",
    "m = 3 #no of clusters\n",
    "norm_s = 1 #\n",
    "norm_x = 1 #\n",
    "bottom = 1/(1+n)  #bij(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b =np.full((n, m), bottom)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.full((m,n),1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially the Bottom-up weights b= [[0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2]] \n",
      "\n",
      "Initially the Top-down weights t =  [[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]] \n",
      "\n",
      "S =  [0 0 0 1]\n",
      "||s|| =  1 \n",
      "\n",
      "y = bij*xi  [0.2 0.2 0.2]\n",
      "Winner J =  0 \n",
      "\n",
      "xi = Si*tJi =  [0 0 0 1]\n",
      "||x|| 1\n",
      "||x||/||s|| =  1.0\n",
      "rho =  0.4\n",
      "Reset is False \n",
      "\n",
      "bij(new) =  [[0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [1.  0.2 0.2]] \n",
      "\n",
      "tji(new) =  [[0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]] \n",
      "\n",
      "S =  [0 1 0 1]\n",
      "||s|| =  2 \n",
      "\n",
      "y = bij*xi  [1.  0.4 0.4]\n",
      "Winner J =  0 \n",
      "\n",
      "xi = Si*tJi =  [0 0 0 1]\n",
      "||x|| 1\n",
      "||x||/||s|| =  0.5\n",
      "rho =  0.4\n",
      "Reset is False \n",
      "\n",
      "bij(new) =  [[0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [1.  0.2 0.2]] \n",
      "\n",
      "tji(new) =  [[0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]] \n",
      "\n",
      "S =  [0 0 1 1]\n",
      "||s|| =  2 \n",
      "\n",
      "y = bij*xi  [1.  0.4 0.4]\n",
      "Winner J =  0 \n",
      "\n",
      "xi = Si*tJi =  [0 0 0 1]\n",
      "||x|| 1\n",
      "||x||/||s|| =  0.5\n",
      "rho =  0.4\n",
      "Reset is False \n",
      "\n",
      "bij(new) =  [[0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [0.  0.2 0.2]\n",
      " [1.  0.2 0.2]] \n",
      "\n",
      "tji(new) =  [[0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]] \n",
      "\n",
      "S =  [1 0 0 0]\n",
      "||s|| =  1 \n",
      "\n",
      "y = bij*xi  [0.  0.2 0.2]\n",
      "Winner J =  1 \n",
      "\n",
      "xi = Si*tJi =  [1 0 0 0]\n",
      "||x|| 1\n",
      "||x||/||s|| =  1.0\n",
      "rho =  0.4\n",
      "Reset is False \n",
      "\n",
      "bij(new) =  [[0.  1.  0.2]\n",
      " [0.  0.  0.2]\n",
      " [0.  0.  0.2]\n",
      " [1.  0.  0.2]] \n",
      "\n",
      "tji(new) =  [[0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(inputs,b,t,rho,learning_rate,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vigilance parameter in the ART-1 (Adaptive Resonance Theory 1) neural network \n",
    "# controls the degree of tolerance for pattern matching or recognition. \n",
    "# It determines how similar an input pattern must be to existing memory \n",
    "# patterns to be recognized as a match.\n",
    "\n",
    "# High Vigilance:\n",
    "# A high vigilance value means the network is less tolerant of differences between input and stored patterns.\n",
    "# It requires input patterns to closely match existing memory patterns for recognition.\n",
    "# This can lead to fewer false recognitions but may also result in the network being overly selective.\n",
    "\n",
    "# Low Vigilance:\n",
    "# A low vigilance value means the network is more tolerant of differences between input and stored patterns.\n",
    "# It allows input patterns with more differences to be recognized as matches to existing memory patterns.\n",
    "# This can lead to more false recognitions but may also result in the network being more adaptive to variations in input patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
